# 2021ESE-Mooyaho_team
## FALL - DETECTION PART
   


**1. Fall-Detection 개요**   
도심 외곽지역의 이용객이 적은 정류장을 이용하는 승객의 안전을 보장하기 위해 쓰러짐을 감지하는 시스템을 의미한다. 알고리즘 진행은 다음과 같다. 카메라를 통해 얻어온 이미지에서 인공지능 모델을 이용해 사람을 감지하고, 추가적인 내부 연산을 통해 사람이 쓰러졌음을 판단한다. 그 다음, 일정 시간동안 쓰러짐이 유지되면 SFTP 프로토콜을 이용해 서버에 이미지를 전송하고, 버스 API를 이용해 해당 정류장에 가장 먼저 도착 예정인 버스의 정보(UID 등)을 얻은 후, DB에 접근해 해당 버스의 FALL-D SIG 플래그를 올린다. 버스 기사 단말기는 서버에 주기적으로 접속해 FALL-D SIG가 올라가 있다면 서버에 저장된 이미지를 받아와 팝업을 띄운다. 이를 통해 버스기사는 사고 발생 현장을 제일 먼저 목격하고 조치를 취하도록 유도한다.
   
   
**2. 알고리즘 구현**   
Fall-Detection 기초 구현과 이미지 전송 과정을 알고리즘 진행 순서대로 설명한다.

**가) 객체 인식**
웹캠에서 실시간으로 얻어오는 이미지들을 Yolov3-416 사물인식 인공지능 모델을 이용해 객체들을 인식한다. 최종적으로는 사람, 자전거, 개, 휴대전화 등등 무수히 많은 사물이 인식된다. 하지만 Fall-detection 알고리즘에서 필요한 객체는 사람뿐이므로, 사람 이외에 인식된 모든 객체들은 무시하고, 오직 사람에 대해서만 ROI 박스가 그려지게 수정했다. 아래 사진 중 왼쪽이 수정 전, 오른쪽이 수정 후이다.   
![image](https://user-images.githubusercontent.com/74461222/119269316-0dbfea80-bc32-11eb-8541-902da8b4a0c6.png)![image](https://user-images.githubusercontent.com/74461222/119269326-16b0bc00-bc32-11eb-9f17-d10e4acc39b4.png)


**나) 쓰러짐 인식**   
인공지능 모델을 이용해 얻은 사람의 ROI 박스 크기를 참조해 쓰러짐을 판별한다. 박스의 width를 height로 나눈 값이 1.1보다 크다면 사람이 쓰러진 상태라고 판단한다. 즉, 사람에 그려진 박스가 가로로 넓어진다면 쓰러진 상태라고 판단하는 것이다.   
![image](https://user-images.githubusercontent.com/74461222/119269364-4f509580-bc32-11eb-819b-c03f5e072a9b.png)![image](https://user-images.githubusercontent.com/74461222/119269367-52e41c80-bc32-11eb-9cd5-c2cb3017dc27.png)   

**다) 쓰러진 이미지 저장**   
사람이 쓰러져있는 이미지를 버스 기사 단말기에 보내기 위해서는 먼저 젯슨 보드 내에 이미지를 저장할 필요가 있다. 그러나 쓰러짐이 감지되었을 때 바로 이미지를 저장하고 전송한다면, 넘어진 상태가 아닌데 잘못 인식했을 경우가 있을 수 있다.   
![image](https://user-images.githubusercontent.com/74461222/119269449-bc642b00-bc32-11eb-9001-81a08154eb25.png)   
카메라 1대로는 쓰러짐이 인식이 안되는 경우가 있었다. 이를 해결하기 위해 다음과 같이 각각 다른 높이, 각도로 설치된 2대의 카메라를 통해 쓰러짐을 감지하도록 구현했다.

<img src = "https://user-images.githubusercontent.com/74461222/122674215-1266c700-d20f-11eb-9793-469281700c98.png" width="300" height="300"><img src = "https://user-images.githubusercontent.com/74461222/122674218-17c41180-d20f-11eb-9c92-9ef5291be2e9.png" width="300" height="300">



위 사진처럼 사람이 카메라 앞으로 가까이 지나가서 ROI 박스의 가로가 넓게 측정될 수도 있으므로, 쓰러짐이 지속적으로 감지될 때부터 진짜 사고가 일어났다고 인지한다. 따라서 쓰러짐이 6초 이상 감지될 때부터 이미지를 젯슨 보드 내에 저장하도록 하는 기능을 추가했다. 이 때, 이미지는 계속 한 파일에 덮어씌운다. 6초 이상을 기준으로 한 이유는, 한 장의 이미지가 Yolov3-416 모델을 통해 객체 인식이 될 때의 시간이 약 0.6초(평균 fps = 1.67) 걸렸기 때문이다. 즉, 최소 이미지 10장이 처리될 동안 쓰러짐이 유지된다면, 젯슨 보드 내에 해당 이미지가 지속적으로 저장된다.

**라) 이미지 전송**   
젯슨 보드 내에 저장된 이미지를 서버에 전송하기 위해서 SSH 파일 전송 프로토콜(Secure File Transfer Protocol, SFTP)을 이용한다.
기본적인 전송 과정은 다음과 같다. 쓰러짐이 지속되어 이미지가 덮어씌워져 저장된다면, 해당 이미지의 수정시간이 갱신될 것이다. 만약 수정시간이 갱신되었다면, 쓰러짐이 새로 발생했다는 의미이므로, 해당 이미지를 SFTP 프로토콜을 이용해 웹서버에 전송한다. 이후, 무한루프에 빠지게 되어 젯슨 내의 이미지 파일의 수정시간이 갱신될 때까지 기다린다. 이 과정을 무한히 반복하게 된다. 


**마) DB 접근 후, FALL-D SIG 플래그 수정**   
쓰러짐이 지속적으로 발생해서 이미지를 서버로 전송한 후, 가장 가까운 버스에게 쓰러짐 이미지를 받아가야 한다는 신호를 주어야 한다. 이것을 위해 웹서버 DB에 FALL-D SIG라는 플래그를 추가한 상태이다.
젯슨 보드는 쓰러짐 이미지를 클라우드 서버에 전송한 후, 버스 API를 이용해 해당 정류장에 가장 가까이 있는 버스에 대한 정보(UID 등)을 얻어온다. 이후, DB에 접근해 가장 가까이 있는 버스의 FALL-D SIG를 해당 버스 UID로 올린다. 그리고 쓰러짐이 감지되지 않는다면 해당 플래그를 0으로 다시 내린다. 이 기능을 구현한다면, 추후에 버스 기사 단말기가 서버에 접근해서 FALL-D SIG가 올라갔을 때 쓰러짐 이미지를 받아갈 수 있을 것이다.


**3. Fall-Detection 구현 영상**      
여러 가지 상황에서의 Fall-Detection 시연 영상을 촬영했다.

**가) 카메라 2대를 이용한 쓰러짐 인식**


https://user-images.githubusercontent.com/74461222/122674640-10056c80-d211-11eb-99fb-4cca2b2cefa2.mp4


**나) 여러 사람이 있을 때 쓰러짐 인식**


https://user-images.githubusercontent.com/74461222/122674651-185da780-d211-11eb-9135-6a6fe88a7da6.mp4


**다) 야간 상황에서의 쓰러짐 인식**


https://user-images.githubusercontent.com/74461222/122674659-214e7900-d211-11eb-891e-0c914185a4a5.mp4


----
